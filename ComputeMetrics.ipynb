{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76fe4ebd-9632-4e5b-8bed-dc0602ca3f0d",
   "metadata": {},
   "source": [
    "## Download Validation Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506b3b82-089f-4f37-85e6-9e6b0961e6b4",
   "metadata": {},
   "source": [
    "First, you'll need to download the validation sequences along with some additional info.\n",
    "\n",
    "Download [this archive] and extract it into `$HOOD_DATA/aux_data/validation_sequences`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9f03e6-4c68-4ead-b0a2-e3ea27b23e28",
   "metadata": {},
   "source": [
    "## set enviromental variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fdea32-a16b-4d49-baa4-0a42dbf0996b",
   "metadata": {},
   "source": [
    "Make sure you set these two enviromental variables:\n",
    "\n",
    "* `HOOD_PROJECT` should lead to the HOOD repository\n",
    "* `HOOD_DATA` should lead to a data folder (see `README.md` for details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc24b6e-c534-4ba3-9622-feeebf045d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOOD_PROJECT = \"/path/to/hood/repository\"\n",
    "HOOD_DATA = \"/path/to/hood/data\"\n",
    "\n",
    "os.environ[\"HOOD_PROJECT\"] = HOOD_PROJECT\n",
    "os.environ[\"HOOD_DATA\"] = HOOD_DATA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed6d198-dd19-4052-9211-80e57472c111",
   "metadata": {},
   "source": [
    "# compute by-frame metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e695e-f4a2-4fe1-85d6-77a415626f0f",
   "metadata": {},
   "source": [
    "Once you have downloaded the validation sequences you can compute metrics for each frame in them. \n",
    "\n",
    "To do that, use `compute_and_store_metrics` function.\n",
    "\n",
    "This function will build a `runner` object with a set of criterions according to the `configs/aux/metrics.yaml` configuraion file. Then it will construct a `Batch` object for each time step in the validation sequences and pass is through `runner.criterion_pass()` to compute metrics.\n",
    "\n",
    "### Canonical geometries\n",
    "Some of the criterions require a canonical geometry of the garment (e.g. stretching loss computes discrepancy betweet triangle areas between current and canonical geometry).\n",
    "\n",
    "Since in our paper we compared our method with [SNUG](http://mslab.es/projects/SNUG/) and [SSCH](http://mslab.es/projects/SelfSupervisedGarmentCollisions/), we used the canonical geometries generated by these methods to compute metrics. These canonical geometries are stored in `$HOOD_DATA/aux_data/validation_sequences/rest_geometries`\n",
    "\n",
    "### Fixed shape parameters\n",
    "For evaluation we have sampled random shape parameters for SMPL from U(-2, 2) for each sequence and then kept them consistent across all compared methods. \n",
    "\n",
    "The randomly sampled beta parameters are stored in `$HOOD_DATA/aux_data/validation_sequences/betas.pkl`.\n",
    "\n",
    "The `.csv` data splits used for validation sequences (`$HOOD_DATA/aux_data/validation_sequences/data_splits`) store an index of the shape parameters for each sequence that maps the sequences to the betas stored in `betas.pkl`\n",
    "\n",
    "\n",
    "### Output files\n",
    "Computed by-frame metrics are stored in `.pkl` files in `$HOOD_DATA/aux_data/validation_sequences/metrics/vs_X.pkl`, where `X` is either `snug` and `ssch` for metrics computed with canonical geometries from the corresponding method.\n",
    "\n",
    "Further in this notebook we demonstrate how to display aggregated metrics used in Table 1 of the paper and Tables 1 and 2 of the supplementary material.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6b4d2-a2e2-425e-840a-53b1b6c03c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.arguments import load_params, create_modules\n",
    "from utils.common import move2device, pickle_load\n",
    "import torch, pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from torch_geometric.data import Batch\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.metrics import compute_and_store_metrics, print_metrics_vs_baselines, print_metrics_vs_sota\n",
    "\n",
    "from utils.defaults import DEFAULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06091998-f101-494d-aa4c-068ef27a1c38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seqs_root = Path(DEFAULTS.aux_data) / 'validation_sequences' / 'hood_rollouts'\n",
    "out_root = Path(DEFAULTS.aux_data) / 'validation_sequences' / 'metrics' \n",
    "canonicalpos_root = Path(DEFAULTS.aux_data) / 'validation_sequences' / 'rest_geometries' \n",
    "datasplit_root = Path(DEFAULTS.aux_data) / 'validation_sequences' / 'data_splits' \n",
    "\n",
    "compute_and_store_metrics(out_root, seqs_root, canonicalpos_root, datasplit_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994eb5d-2100-4a42-97ef-31d1988dd382",
   "metadata": {},
   "source": [
    "# Print aggregeted metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a275dd-daf2-45b7-96f6-994904af6a6e",
   "metadata": {},
   "source": [
    "## Table 1 of the main paper and Table 2 of the supplementary material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e1732b-72b2-4b0c-8b3c-b22d7fb6b93c",
   "metadata": {},
   "source": [
    "To produce the numbers that precisely match the paper, use parameter `match_paper=True` (it excludes one of the sequences from comparison, for which the baseline `Fine15` diverged).\n",
    "\n",
    "To average the metrics across all sequences (e.g. if you want to compare your results to HOOD), use `match_paper=False`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9e1a4-fd37-4186-9f34-b598233323bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_root = Path(DEFAULTS.aux_data) / 'validation_sequences' / 'metrics'\n",
    "print_metrics_vs_baselines(metrics_root, match_paper=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9628ac-6fc9-4054-ba13-4473dae1858a",
   "metadata": {},
   "source": [
    "## Table 1 of the supplementary material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e56ec1-fb0c-46a2-a9a4-cafade7e1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics_vs_sota(metrics_root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hood_public2",
   "language": "python",
   "name": "hood_public2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
